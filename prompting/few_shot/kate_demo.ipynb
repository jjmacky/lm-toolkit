{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KATE (kNN-Augmented in-conText Example selection)\n",
    "This notebook demonstrates the KATE method, which enhances few-shot learning by selecting semantically-similar in-context examples for a given test sample. KATE was proposed in [\"What Makes Good In-Context Examples for GPT-3?\" Liu et al. (2021)](https://arxiv.org/pdf/2101.06804). Note that KATE was proposed in January of 2021. Models and RAG methods have both advanced since that time. See documentation here for a detailed description of KATE.\n",
    "\n",
    "KATE works best when the retrieved examples significantly boost the model's ability to generate appropriate responses. In this example, we embed a training dataset with masked personally identifiable information (PII). During inference, we draw a random sentence from the validation dataset and use KATE to find the k nearest neighbors from the training data. These neighbors are compiled into a prompt, which, along with the inference sentence, is used to generate a response from the language model, Llama3 (8B) in this example. This is a unique application of KATE and was not originally proposed in the paper.\n",
    "\n",
    "This is not meant to be a full evaluation and benchmarking of KATE with respect to a PII masking activity. Instead, we look at a single inference sentence as a simple working example of the KATE model in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset from Hugging Face\n",
    "For this example I'm using pii-masking-300k, which can be found [here](https://huggingface.co/datasets/ai4privacy/pii-masking-300k?row=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ai4privacy/pii-masking-300k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import ollama\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', output_attentions=False)\n",
    "model = RobertaModel.from_pretrained('roberta-base', output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "# Function to generate embeddings for a given text using RoBERTa\n",
    "def get_roberta_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Average pooling of last hidden state\n",
    "\n",
    "# Embed all entries in the dataset, showing progress with tqdm\n",
    "def embed_data(data):\n",
    "    for entry in tqdm(data, desc=\"Embedding entries\"):\n",
    "        embedding = get_roberta_embedding(entry[\"original\"]) # Embed the original sentence to be masked for later comparison during inference\n",
    "        entry[\"embedding\"] = embedding\n",
    "    return data\n",
    "\n",
    "# Calculate similarity between a new text and the dataset, returning top k similar indices\n",
    "def calculate_similarity(new_text_embedding, data, k=5):\n",
    "    similarity_scores = cosine_similarity([new_text_embedding], [d[\"embedding\"] for d in data])[0]\n",
    "    top_k_indices = np.argpartition(similarity_scores, -k)[-k:] # Only do a partial sort the entire dataset for efficiency\n",
    "    top_k_indices = top_k_indices[np.argsort(similarity_scores[top_k_indices])][::-1] # Quickly sort the top indices\n",
    "    return top_k_indices\n",
    "\n",
    "# Generate example masked sentences from the most similar entries\n",
    "def get_example_masked_sentences(top_k_indices, data):\n",
    "    example_masked_sentences = \"\\n\\n\".join(\n",
    "        f\"Original sentence:{data[index]['original']}\\n\\nMasked sentence:{data[index]['masked']}\"\n",
    "        for index in top_k_indices\n",
    "    )\n",
    "    return example_masked_sentences\n",
    "\n",
    "# Build a prompt for the language model using examples and the sentence to mask\n",
    "def build_model_prompt(example_masked_sentences, sentence_to_mask):\n",
    "    template = \"\"\"\n",
    "        Please mask the PII in the given sentence by following the examples:\n",
    "\n",
    "        {examples}\n",
    "\n",
    "        Here is the sentence to mask. Respond only with the masked sentence and no additional explanation or commentary:\n",
    "        Sentence to mask: {sentence}\n",
    "        Masked sentence:\n",
    "        \"\"\"\n",
    "    \n",
    "    return template.format(\n",
    "        examples=example_masked_sentences,\n",
    "        sentence=sentence_to_mask\n",
    "    )\n",
    "\n",
    "# Call the language model to perform PII masking during inference\n",
    "def call_model(prompt, llm_model):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = ollama.chat(model=llm_model, messages=messages, stream=False)\n",
    "    result = response['message']['content']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and embed data\n",
    "Create a simplified list from the original dataset. For simplicity I'm not including the mask list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset:: 100%|██████████| 177677/177677 [00:59<00:00, 2989.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data = []\n",
    "for index in tqdm(range(len(dataset['train'])), desc=\"Creating dataset:\"):\n",
    "    data.append({\"original\": dataset['train'][index]['source_text'], \"masked\":dataset['train'][index]['target_text']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed the data. Here I'm choosing to embed the training dataset, with is 79% of the total dataset. This can take a while (~3 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding entries: 100%|██████████| 177677/177677 [3:15:49<00:00, 15.12it/s]  \n"
     ]
    }
   ],
   "source": [
    "embedded_data = embed_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference\n",
    "Perform inference on a test sentence. We'll use the validation set to draw a random sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked sentence from model: - Immunization_Certification:\n",
      "    individuals:\n",
      "      - [TITLE]\n",
      "      - [BOD]\n",
      "      - [TEL]\n",
      "      - [COUNTRY]\n",
      "      - [BUILDING]\n",
      "      - [STREET]\n",
      "      - [CITY]\n",
      "      - [STATE]\n",
      "      - [POSTCODE]\n",
      "      - [SECADDRESS]\n",
      "      - [TIME]\n",
      "      - [LASTNAME1]\n",
      "    background:\n",
      "      - [DATE]\n",
      "Masked ground-truth sentence from data: ```yaml\n",
      "- Immunization_Certification:\n",
      "    individuals:\n",
      "      - [TITLE]\n",
      "      - [USERNAME]\n",
      "      - [TEL]\n",
      "      - [COUNTRY]\n",
      "      - [BUILDING]\n",
      "      - [STREET]\n",
      "      - [CITY]\n",
      "      - [STATE]\n",
      "      - [POSTCODE]\n",
      "      - [SECADDRESS]\n",
      "      - [TIME]\n",
      "      - [LASTNAME1]\n",
      "    background:\n",
      "      - [DATE]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Pick random sentence from validation set to use as a test of the approach\n",
    "random.seed(11) # Seed seed for reproducibility\n",
    "rand_index = np.random.choice(len(dataset['validation']), 1) # I forgot to set a random seed initially :/ , but I used index 1919 for this example.\n",
    "rand_index = 1919 # If you want to follow my example\n",
    "\n",
    "test_sentence = dataset['validation'][rand_index]['source_text']\n",
    "target_sentence = dataset['validation'][rand_index]['target_text']\n",
    "\n",
    "# Get similar sentence for our test sentence in our embedded data\n",
    "embedded_test_sentence = get_roberta_embedding(test_sentence)\n",
    "top_k_indices = calculate_similarity(embedded_test_sentence, embedded_data)\n",
    "\n",
    "# Build the model prompt\n",
    "example_masked_sentences = get_example_masked_sentences(top_k_indices, embedded_data)\n",
    "prompt = build_model_prompt(example_masked_sentences, test_sentence)\n",
    "\n",
    "# Get the masked sentence\n",
    "masked_sentence = call_model(prompt, \"llama3\")\n",
    "\n",
    "# Compare the masked sentence from our model with the ground truth from the data\n",
    "print(f\"Masked sentence from model: {masked_sentence}\")\n",
    "print(f\"Masked ground-truth sentence from data: {target_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional investigations\n",
    "If desired we can look at the top examples to see how qualitatively similar they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 37315, 137934,  23227, 137935,  23229])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00\n",
      "      - 8207886065\n",
      "      - 974312500\n",
      "      - +132 289 676-9075\n",
      "      - United States\n",
      "      - 332\n",
      "      - Rochelle Street\n",
      "      - New York\n",
      "      - NY\n",
      "      - 10464\n",
      "      - Flat 298\n",
      "      - ~`4teF\n",
      "      - Langmeier\n",
      "      - COMMENTS_C: \"Conduct IP audit, update trademark portfolio, support patent applications process.\"\n",
      "    background:\n",
      "      6:30 AM\n",
      "      31st October 2027\n",
      "```\n",
      "00:00\n",
      "      - [IDCARD]\n",
      "      - [PASSPORT]\n",
      "      - [TEL]\n",
      "      - [COUNTRY]\n",
      "      - [BUILDING]\n",
      "      - [STREET]\n",
      "      - [CITY]\n",
      "      - [STATE]\n",
      "      - [POSTCODE]\n",
      "      - [SECADDRESS]\n",
      "      - [PASS]\n",
      "      - [LASTNAME1]\n",
      "      - COMMENTS_C: \"Conduct IP audit, update trademark portfolio, support patent applications process.\"\n",
      "    background:\n",
      "      [TIME]\n",
      "      [DATE]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(data[23229]['original'])\n",
    "print(data[23229]['masked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approaches\n",
    "First, we can just try asking the model to mask the sentence. This is also a good check to see if there is data contamination. If the model memorized the PII dataset it might achieve strong zero-shot masking without much direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help!\n",
      "\n",
      "Here is the modified sentence with personally identifiable information masked:\n",
      "\n",
      "```\n",
      "yaml\n",
      "- Immunization_Certification:\n",
      "  individuals:\n",
      "    - Princess\n",
      "    - XXXXXXXXXXXXXXXXXX\n",
      "    - XXXXXXXX\n",
      "    - United Kingdom\n",
      "    - XXXX\n",
      "    - Fleming Way\n",
      "    - Swindon\n",
      "    - ENG\n",
      "    - SN1 2NN\n",
      "    - Townhouse 90\n",
      "    - 05:59\n",
      "    - Morag\n",
      "  background:\n",
      "    - XXXX/09/1972\n",
      "```\n",
      "\n",
      "I replaced the following personally identifiable information:\n",
      "\n",
      "* Phone number: XXXXXXXX\n",
      "* Date of birth: XXXX/09/1972 (only the year is masked, as the rest is publicly available information)\n",
      "* Person's name: hlfiadjwhwi16966 and Morag are likely names that should be kept confidential. I replaced them with generic placeholder text.\n",
      "\n",
      "Let me know if you have any further requests!\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"Please mask the personally identifiable information in this sentence: {test_sentence}\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "response = ollama.chat(model=\"llama3\", messages=messages, stream=False)\n",
    "result = response['message']['content']\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can be more sophisticated and give the model the list of masks available. This achieves decent performance, but still not quite as good as providing explicit examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the masked sentence:\n",
      "\n",
      "```\n",
      "Immunization_Certification:\n",
      "  individuals:\n",
      "    - Princess\n",
      "    - [SOCIALNUMBER]\n",
      "    - +[TEL]\n",
      "    - [COUNTRY]\n",
      "    - [DATE]\n",
      "    - [STREET]\n",
      "    - [POSTCODE]\n",
      "    - [SECADDRESS]\n",
      "    - [TIME]\n",
      "    - Morag\n",
      "  background:\n",
      "    - [DATE]\n",
      "```\n",
      "\n",
      "I used the following masks:\n",
      "\n",
      "* [SOCIALNUMBER] to mask the social number (hlfiadjwhwi16966)\n",
      "* +[TEL] to mask the phone number (+22-252 178-7818)\n",
      "* [COUNTRY] to mask the country (United Kingdom)\n",
      "* [DATE] to mask the date of birth (23/09/1972)\n",
      "* [STREET] to mask the street address (Fleming Way)\n",
      "* [POSTCODE] to mask the postcode (SN1 2NN)\n",
      "* [SECADDRESS] to mask the secondary address (Townhouse 90)\n"
     ]
    }
   ],
   "source": [
    "masks = \"[BOD], [BUILDING], [CITY], [COUNTRY], [DATE], [DRIVERLICENSE], [EMAIL], [GEOCOORD], [GIVENNAME1], [GIVENNAME2], [IDCARD], [IP], [LASTNAME1], [LASTNAME2], [LASTNAME3], [PASS], [POSTCODE], [SECADDRESS], [SEX], [SOCIALNUMBER], [STATE], [STREET], [TEL], [TIME], [TITLE], [USERNAME]\"\n",
    "prompt = f\"You have the following list of masks available: {masks}.\\n\\n Please mask the personally identifiable information in this sentence using the appropriate mask: {test_sentence}\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "response = ollama.chat(model=\"llama3\", messages=messages, stream=False)\n",
    "result = response['message']['content']\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test if KATE outperforms using random examples chosen from the dataset rather than the k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked sentence from model: Here is the masked sentence:\n",
      "\n",
      "- Immunization_Certification:\n",
      "  individuals:\n",
      "    - [NAME1]\n",
      "    - [USERNAME]\n",
      "    - [PHONE_NUMBER]\n",
      "    - [COUNTRY]\n",
      "    - [NUMBER]\n",
      "    - [STREET_ADDRESS]\n",
      "    - [CITY]\n",
      "    - [STATE]\n",
      "    - [POSTAL_CODE]\n",
      "    - [ADDRESS_LINE2]\n",
      "    - [TIME]\n",
      "    - [NAME2]\n",
      "  background:\n",
      "    - [DATE]\n",
      "Masked ground-truth sentence from data: ```yaml\n",
      "- Immunization_Certification:\n",
      "    individuals:\n",
      "      - [TITLE]\n",
      "      - [USERNAME]\n",
      "      - [TEL]\n",
      "      - [COUNTRY]\n",
      "      - [BUILDING]\n",
      "      - [STREET]\n",
      "      - [CITY]\n",
      "      - [STATE]\n",
      "      - [POSTCODE]\n",
      "      - [SECADDRESS]\n",
      "      - [TIME]\n",
      "      - [LASTNAME1]\n",
      "    background:\n",
      "      - [DATE]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "random_top_k_indices = np.random.choice(range(len(data)), k)\n",
    "example_masked_sentences = get_example_masked_sentences(random_top_k_indices, data)\n",
    "prompt = build_model_prompt(example_masked_sentences, test_sentence)\n",
    "masked_sentence = call_model(prompt, \"llama3\")\n",
    "\n",
    "# Compare the masked sentence from our model with the ground truth from the data\n",
    "print(f\"Masked sentence from model: {masked_sentence}\")\n",
    "print(f\"Masked ground-truth sentence from data: {target_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
